{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad21910f-e8a8-4f7a-aa5e-959ebb108c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import yaml\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Custom YOLOv10 implementation or pre-trained weights loading\n",
    "from yolov10 import YOLOv10Model  # Replace with actual YOLOv10 implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8716df-a71e-41f1-b84c-e4a961dbe485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import yaml\n",
    "\n",
    "def convert_annotations_to_yaml(class_dir, output_yaml):\n",
    "    annotations = []\n",
    "    \n",
    "    for class_name in os.listdir(class_dir):\n",
    "        class_path = os.path.join(class_dir, class_name)\n",
    "        img_folder = os.path.join(class_path, 'img')  # Folder with image frames\n",
    "        gt_file = os.path.join(class_path, 'groundtruth_rect.txt')\n",
    "        \n",
    "        if not os.path.exists(gt_file):\n",
    "            continue\n",
    "        \n",
    "        with open(gt_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        objects = []\n",
    "        for line in lines:\n",
    "            bbox = list(map(float, line.strip().split()))\n",
    "            objects.append({\n",
    "                'bbox': bbox\n",
    "            })\n",
    "        \n",
    "        for img_file in os.listdir(img_folder):\n",
    "            if img_file.endswith('.jpg'):\n",
    "                annotations.append({\n",
    "                    'image': os.path.join(class_name, 'img', img_file),\n",
    "                    'objects': objects\n",
    "                })\n",
    "    \n",
    "    with open(output_yaml, 'w') as f:\n",
    "        yaml.dump(annotations, f, default_flow_style=False)\n",
    "\n",
    "# Usage\n",
    "dataset_dir = 'path/to/your/dataset'\n",
    "output_yaml_file = 'annotations.yaml'\n",
    "convert_annotations_to_yaml(dataset_dir, output_yaml_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f55c53d-d317-4746-9660-ba677fa81dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(image, label):\n",
    "    transform = A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.2),\n",
    "        A.Rotate(limit=45, p=0.5),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "    \n",
    "    augmented = transform(image=image)\n",
    "    return augmented['image'], label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4331a4-371b-46e9-a90c-eb11f0eda2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_yaml(yaml_file):\n",
    "    with open(yaml_file, 'r') as f:\n",
    "        data = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for item in data:\n",
    "        img_path = item['image']\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (416, 416))\n",
    "        img = img / 255.0  # Normalize\n",
    "        \n",
    "        bbox = [obj['bbox'] for obj in item['objects']]\n",
    "        labels.append(bbox)\n",
    "        images.append(img)\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load data\n",
    "X, y = load_data_from_yaml(output_yaml_file)\n",
    "\n",
    "# Split data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define YOLOv10 model\n",
    "model = YOLOv10Model(input_shape=(416, 416, 3), num_classes=32)  # Adjust num_classes as needed\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training loop\n",
    "history = model.fit(\n",
    "    X_train, y_train, \n",
    "    validation_data=(X_val, y_val), \n",
    "    batch_size=16, epochs=50\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "val_predictions = model.predict(X_val)\n",
    "print(classification_report(np.argmax(y_val, axis=1), np.argmax(val_predictions, axis=1)))\n",
    "print(confusion_matrix(np.argmax(y_val, axis=1), np.argmax(val_predictions, axis=1)))\n",
    "\n",
    "# Save the model\n",
    "model.save('coraltrack_yolov10_model.h5')\n",
    "\n",
    "# Visualize some predictions\n",
    "def visualize_predictions(images, predictions, true_labels):\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    for i in range(9):\n",
    "        plt.subplot(3, 3, i+1)\n",
    "        plt.imshow(images[i])\n",
    "        pred = np.argmax(predictions[i])\n",
    "        true = np.argmax(true_labels[i])\n",
    "        plt.title(f\"Pred: {pred}, True: {true}\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Visualize predictions on validation data\n",
    "visualize_predictions(X_val, val_predictions, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479c31b8-af8f-4487-bb36-2babc4be2efb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
